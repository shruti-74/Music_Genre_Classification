ğŸµ Music Genre Classification with CNN & Spectrograms
A deep learning project that classifies music genres by converting audio files into spectrogram images and training a Convolutional Neural Network (CNN).
Built using Python, Librosa, Matplotlib, and TensorFlow/Keras, and trained on the GTZAN Dataset.

ğŸ¯ Goal
Automatically predict the genre of a given music clip using spectrogram-based image classification.

ğŸ§° Tech Stack
Python 3.x

Librosa â€“ Audio processing & feature extraction

Matplotlib â€“ Spectrogram generation

NumPy & Pandas â€“ Data handling

TensorFlow / Keras â€“ CNN model building and training

OpenCV (optional) â€“ For preprocessing or visualization

ğŸ¼ Dataset
GTZAN Music Genre Dataset

10 Genres: blues, classical, country, disco, hiphop, jazz, metal, pop, reggae, rock

100 audio tracks per genre (1000 total)

Format: .wav, 30 sec each

Source: Marsyas/GTZAN

ğŸ”„ Workflow
Load Audio Files using librosa

Convert to Spectrograms (Mel Spectrogram or MFCCs)

Save Spectrograms as Images

Preprocess Images (resize, normalize)

Build CNN Model

Train & Evaluate

Predict Genre of New Audio

ğŸ“ Folder Structure
bash
Copy code
ğŸ“¦ music-genre-classification
â”œâ”€â”€ genres_original/           # Raw GTZAN .wav files
â”œâ”€â”€ images/                    # Generated spectrograms per genre
â”œâ”€â”€ models/                    # Saved CNN models
â”œâ”€â”€ notebooks/                 # Jupyter notebooks for EDA and model training
â”œâ”€â”€ main.py                    # Main training script
â”œâ”€â”€ predict.py                 # For genre prediction on new audio
â”œâ”€â”€ utils.py                   # Helper functions
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ“Š Model Architecture (Example)
text
Copy code
Input: 128x128x3 spectrogram image
â†’ Conv2D + ReLU + MaxPooling
â†’ Conv2D + ReLU + MaxPooling
â†’ Flatten
â†’ Dense + Dropout
â†’ Dense (10 units, softmax)
ğŸš€ Getting Started
âœ… Install Dependencies
bash
Copy code
pip install librosa matplotlib tensorflow opencv-python numpy pandas
ğŸ›  Preprocess Audio
Convert .wav files to spectrograms:

python
Copy code
import librosa
import matplotlib.pyplot as plt

y, sr = librosa.load('genres_original/jazz/jazz.00054.wav')
S = librosa.feature.melspectrogram(y, sr=sr)
librosa.display.specshow(librosa.power_to_db(S), sr=sr)
plt.savefig('images/jazz/jazz00054.png')
ğŸ“ Train the Model
bash
Copy code
python main.py
ğŸ” Predict Genre
bash
Copy code
python predict.py --file my_song.wav
ğŸ“ˆ Results
Accuracy: ~85-90% (after tuning)

Confusion Matrix, F1 Score, etc. can be included

ğŸ§  Highlights
Uses spectrograms as input instead of raw audio

CNN treats music as an image classification task

Supports adding your own genres with minimal changes

Easily extendable with RNNs, CRNNs, or transfer learning
